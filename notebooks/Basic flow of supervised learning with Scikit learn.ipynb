{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of the Supervised Learning Steps with A Simple Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules and load data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt, matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "labeled_images = pd.read_csv('..\\\\data\\\\digits_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview the first five row of the origninal dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_images.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examing the data, view first 25 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "f,ax=plt.subplots(5,5,figsize=(8,8)) #set up a 5 by 5 plotting area\n",
    "for i in range (1,26):\n",
    "    img=labeled_images.iloc[i,1:].as_matrix()#convert pandas datafrme into numpy arrays\n",
    "    img=img.reshape((28,28)) #reshape into 28 by 28 pixels\n",
    "    n=math.ceil(i/5)-1 #math.ceil to round up\n",
    "    m=[0,1,2,3,4]*5\n",
    "    ax[m[i-1], n].imshow(img)\n",
    "    ax[m[i-1], n].set_title(labeled_images.iloc[i,0])\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of the input data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original input dataset shape is:  (42000, 785)\n",
      "The X dataset shape is:  (2000, 784)\n",
      "The y dataset shape is:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "#select images features from the second column to the last column, and only the first 2000 smaples(rows).\n",
    "X = labeled_images.iloc[:2000,1:]\n",
    "\n",
    "#select the first column which is the label, or the digit, and only the first 2000 smaples(rows).\n",
    "y = labeled_images.iloc[:2000,:1].squeeze()# with .squeeze(), the pandas one column dataframe is turned into a series \n",
    "\n",
    "print('The original input dataset shape is: ', labeled_images.shape)\n",
    "print('The X dataset shape is: ',X.shape)\n",
    "print('The y dataset shape is: ', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train_test_split(X,y,train_size=0.8) split X, y into X_train,X_test,y_train,y_test, by default the split is 75% to 25% for train to test, but you can change the rate with train_size, here it is set 80% as train, and 20% as test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The X_train dataset shape is:  (1600, 784)\n",
      "The y_train dataset shape is:  (1600,)\n",
      "The X_test dataset shape is:  (400, 784)\n",
      "The y_test dataset shape is:  (400,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "print('The X_train dataset shape is: ', X_train.shape)\n",
    "print('The y_train dataset shape is: ', y_train.shape)\n",
    "print('The X_test dataset shape is: ', X_test.shape)\n",
    "print('The y_test dataset shape is: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the X_train,X_test,y_train,y_test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "582        0       0       0       0       0       0       0       0       0   \n",
       "159        0       0       0       0       0       0       0       0       0   \n",
       "1827       0       0       0       0       0       0       0       0       0   \n",
       "318        0       0       0       0       0       0       0       0       0   \n",
       "708        0       0       0       0       0       0       0       0       0   \n",
       "532        0       0       0       0       0       0       0       0       0   \n",
       "485        0       0       0       0       0       0       0       0       0   \n",
       "251        0       0       0       0       0       0       0       0       0   \n",
       "1490       0       0       0       0       0       0       0       0       0   \n",
       "1433       0       0       0       0       0       0       0       0       0   \n",
       "190        0       0       0       0       0       0       0       0       0   \n",
       "1837       0       0       0       0       0       0       0       0       0   \n",
       "616        0       0       0       0       0       0       0       0       0   \n",
       "1484       0       0       0       0       0       0       0       0       0   \n",
       "578        0       0       0       0       0       0       0       0       0   \n",
       "351        0       0       0       0       0       0       0       0       0   \n",
       "1218       0       0       0       0       0       0       0       0       0   \n",
       "1422       0       0       0       0       0       0       0       0       0   \n",
       "1362       0       0       0       0       0       0       0       0       0   \n",
       "942        0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "      pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "582        0    ...            0         0         0         0         0   \n",
       "159        0    ...            0         0         0         0         0   \n",
       "1827       0    ...            0         0         0         0         0   \n",
       "318        0    ...            0         0         0         0         0   \n",
       "708        0    ...            0         0         0         0         0   \n",
       "532        0    ...            0         0         0         0         0   \n",
       "485        0    ...            0         0         0         0         0   \n",
       "251        0    ...            0         0         0         0         0   \n",
       "1490       0    ...            0         0         0         0         0   \n",
       "1433       0    ...            0         0         0         0         0   \n",
       "190        0    ...            0         0         0         0         0   \n",
       "1837       0    ...            0         0         0         0         0   \n",
       "616        0    ...            0         0         0         0         0   \n",
       "1484       0    ...            0         0         0         0         0   \n",
       "578        0    ...            0         0         0         0         0   \n",
       "351        0    ...            0         0         0         0         0   \n",
       "1218       0    ...            0         0         0         0         0   \n",
       "1422       0    ...            0         0         0         0         0   \n",
       "1362       0    ...            0         0         0         0         0   \n",
       "942        0    ...            0         0         0         0         0   \n",
       "\n",
       "      pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "582          0         0         0         0         0  \n",
       "159          0         0         0         0         0  \n",
       "1827         0         0         0         0         0  \n",
       "318          0         0         0         0         0  \n",
       "708          0         0         0         0         0  \n",
       "532          0         0         0         0         0  \n",
       "485          0         0         0         0         0  \n",
       "251          0         0         0         0         0  \n",
       "1490         0         0         0         0         0  \n",
       "1433         0         0         0         0         0  \n",
       "190          0         0         0         0         0  \n",
       "1837         0         0         0         0         0  \n",
       "616          0         0         0         0         0  \n",
       "1484         0         0         0         0         0  \n",
       "578          0         0         0         0         0  \n",
       "351          0         0         0         0         0  \n",
       "1218         0         0         0         0         0  \n",
       "1422         0         0         0         0         0  \n",
       "1362         0         0         0         0         0  \n",
       "942          0         0         0         0         0  \n",
       "\n",
       "[20 rows x 784 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582     7\n",
       "159     6\n",
       "1827    3\n",
       "318     8\n",
       "708     1\n",
       "532     6\n",
       "485     8\n",
       "251     0\n",
       "1490    0\n",
       "1433    1\n",
       "190     2\n",
       "1837    8\n",
       "616     9\n",
       "1484    4\n",
       "578     7\n",
       "351     4\n",
       "1218    1\n",
       "1422    1\n",
       "1362    4\n",
       "942     3\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "405        0       0       0       0       0       0       0       0       0   \n",
       "1190       0       0       0       0       0       0       0       0       0   \n",
       "1132       0       0       0       0       0       0       0       0       0   \n",
       "731        0       0       0       0       0       0       0       0       0   \n",
       "1754       0       0       0       0       0       0       0       0       0   \n",
       "1178       0       0       0       0       0       0       0       0       0   \n",
       "1533       0       0       0       0       0       0       0       0       0   \n",
       "1303       0       0       0       0       0       0       0       0       0   \n",
       "1857       0       0       0       0       0       0       0       0       0   \n",
       "18         0       0       0       0       0       0       0       0       0   \n",
       "1266       0       0       0       0       0       0       0       0       0   \n",
       "1543       0       0       0       0       0       0       0       0       0   \n",
       "249        0       0       0       0       0       0       0       0       0   \n",
       "191        0       0       0       0       0       0       0       0       0   \n",
       "721        0       0       0       0       0       0       0       0       0   \n",
       "1896       0       0       0       0       0       0       0       0       0   \n",
       "452        0       0       0       0       0       0       0       0       0   \n",
       "1947       0       0       0       0       0       0       0       0       0   \n",
       "1544       0       0       0       0       0       0       0       0       0   \n",
       "1205       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "      pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "405        0    ...            0         0         0         0         0   \n",
       "1190       0    ...            0         0         0         0         0   \n",
       "1132       0    ...            0         0         0         0         0   \n",
       "731        0    ...            0         0         0         0         0   \n",
       "1754       0    ...            0         0         0         0         0   \n",
       "1178       0    ...            0         0         0         0         0   \n",
       "1533       0    ...            0         0         0         0         0   \n",
       "1303       0    ...            0         0         0         0         0   \n",
       "1857       0    ...            0         0         0         0         0   \n",
       "18         0    ...            0         0         0         0         0   \n",
       "1266       0    ...            0         0         0         0         0   \n",
       "1543       0    ...            0         0         0         0         0   \n",
       "249        0    ...            0         0         0         0         0   \n",
       "191        0    ...            0         0         0         0         0   \n",
       "721        0    ...            0         0         0         0         0   \n",
       "1896       0    ...            0         0         0         0         0   \n",
       "452        0    ...            0         0         0         0         0   \n",
       "1947       0    ...            0         0         0         0         0   \n",
       "1544       0    ...            0         0         0         0         0   \n",
       "1205       0    ...            0         0         0         0         0   \n",
       "\n",
       "      pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "405          0         0         0         0         0  \n",
       "1190         0         0         0         0         0  \n",
       "1132         0         0         0         0         0  \n",
       "731          0         0         0         0         0  \n",
       "1754         0         0         0         0         0  \n",
       "1178         0         0         0         0         0  \n",
       "1533         0         0         0         0         0  \n",
       "1303         0         0         0         0         0  \n",
       "1857         0         0         0         0         0  \n",
       "18           0         0         0         0         0  \n",
       "1266         0         0         0         0         0  \n",
       "1543         0         0         0         0         0  \n",
       "249          0         0         0         0         0  \n",
       "191          0         0         0         0         0  \n",
       "721          0         0         0         0         0  \n",
       "1896         0         0         0         0         0  \n",
       "452          0         0         0         0         0  \n",
       "1947         0         0         0         0         0  \n",
       "1544         0         0         0         0         0  \n",
       "1205         0         0         0         0         0  \n",
       "\n",
       "[20 rows x 784 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405     5\n",
       "1190    8\n",
       "1132    6\n",
       "731     2\n",
       "1754    0\n",
       "1178    8\n",
       "1533    2\n",
       "1303    0\n",
       "1857    3\n",
       "18      7\n",
       "1266    6\n",
       "1543    7\n",
       "249     1\n",
       "191     1\n",
       "721     9\n",
       "1896    3\n",
       "452     7\n",
       "1947    2\n",
       "1544    0\n",
       "1205    7\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create classifier object\n",
    "\n",
    "We first try multiclass logistic regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier (fit the estimator) using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out the accuracy of training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the accuracy of the classifier on future data, using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the trained classifier model to classify (predict) new, previously unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predicted_y=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is: 5, and the predicted digit is: 5\n",
      "The image is: 8, and the predicted digit is: 8\n",
      "The image is: 6, and the predicted digit is: 6\n",
      "The image is: 2, and the predicted digit is: 2\n",
      "The image is: 0, and the predicted digit is: 0\n",
      "The image is: 8, and the predicted digit is: 8\n",
      "The image is: 2, and the predicted digit is: 2\n",
      "The image is: 0, and the predicted digit is: 0\n",
      "The image is: 3, and the predicted digit is: 3\n",
      "The image is: 7, and the predicted digit is: 7\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('The image is: {0}, and the predicted digit is: {1}'.format(\n",
    "        y_test.reset_index(drop=True)[i],predicted_y[i]))#use reset_index to change the index to [0,..n], drop=True requires not keep the original index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you calculate the accuracy score yourself?\n",
    "\n",
    "You can compare y_test, and predicted_y, and the accuracy score = number of correct classification/number of all samples in the y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of score of the test data is: 83.50%\n"
     ]
    }
   ],
   "source": [
    "accuracy_score=np.mean(predicted_y==y_test)\n",
    "print('The accuracy of score of the test data is: {:.2%}'.format(accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview 1: Which model performs the best with default parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a number of classification models with their default parameters.\n",
    "There are:\n",
    "+ K-Nearest Neighbors\n",
    "+ Logistic Regression Classifier\n",
    "+ Ridge Classifier\n",
    "+ Lasso Classifier\n",
    "+ SGD Classifier\n",
    "+ ElasticNet Classifier\n",
    "+ Support Vector Machine\n",
    "+ Naive Bayes Multinomial Classifier\n",
    "+ Decision Tree Classifier\n",
    "+ Ensembles of Decision Trees (Random Forest classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier,LassoCV,SGDClassifier,ElasticNetCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifier_names=['K-Nearest Neighbors Classifier',\n",
    "                    'Logistic Regression Classifier',\n",
    "                    'Ridge Classifier',\n",
    "                    'Lasso Classifier',\n",
    "                    'SGD Classifier',\n",
    "                    'ElasticNet Classifier',\n",
    "                    'Support Vector Machine',\n",
    "                    'Naive Bayes Multinomial Classifier',\n",
    "                    'Decision Tree Classifier',\n",
    "                    'Random Forest classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "classifiers = [ KNeighborsClassifier(),\n",
    "                LogisticRegression(),\n",
    "                RidgeClassifier(),\n",
    "                LassoCV(),\n",
    "                SGDClassifier(),           \n",
    "                ElasticNetCV(cv=10, random_state=0),\n",
    "                SVC(),\n",
    "                MultinomialNB(),\n",
    "                DecisionTreeClassifier(),           \n",
    "                RandomForestClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbors Classifier has an accuracy score of :93.00% on train data, and 87.00% on test data.\n",
      "Logistic Regression Classifier has an accuracy score of :100.00% on train data, and 83.50% on test data.\n",
      "Ridge Classifier has an accuracy score of :97.38% on train data, and 74.50% on test data.\n",
      "Lasso Classifier has an accuracy score of :63.93% on train data, and 53.54% on test data.\n",
      "SGD Classifier has an accuracy score of :93.12% on train data, and 84.00% on test data.\n",
      "ElasticNet Classifier has an accuracy score of :66.39% on train data, and 53.17% on test data.\n",
      "Support Vector Machine has an accuracy score of :100.00% on train data, and 12.00% on test data.\n",
      "Naive Bayes Multinomial Classifier has an accuracy score of :84.38% on train data, and 80.50% on test data.\n",
      "Decision Tree Classifier has an accuracy score of :100.00% on train data, and 68.50% on test data.\n",
      "Random Forest classifier has an accuracy score of :99.94% on train data, and 81.75% on test data.\n"
     ]
    }
   ],
   "source": [
    "models=zip(classifier_names,classifiers)#combine two lists together as a tuple\n",
    "results=[]#create an empty list to store the results of each classifier\n",
    "\n",
    "for name,clf in models:\n",
    "    model=clf.fit(X_train,y_train)#fit the model\n",
    "    accuracy_score_train=clf.score(X_train, y_train)\n",
    "    accuracy_score_test=clf.score(X_test, y_test)\n",
    "    results.append((name,accuracy_score_train,accuracy_score_test))\n",
    "    \n",
    "for n,a,b in results:    #print the results\n",
    "    print('{0} has an accuracy score of :{1:.2%} on train data, and {2:.2%} on test data.'.format(n,a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results.sort(key=lambda x:x[1],reverse=True)#sort the results by accuracy score on training data\n",
    "results_pd=pd.DataFrame(results,\n",
    "                        columns=['Classifier','Score on training data','Score on test data'\n",
    "                                ])#turn list into pandas dataframe for better display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score on training data</th>\n",
       "      <th>Score on test data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.817500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.973750</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes Multinomial Classifier</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.663894</td>\n",
       "      <td>0.531748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.639250</td>\n",
       "      <td>0.535359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Classifier  Score on training data  \\\n",
       "0      Logistic Regression Classifier                1.000000   \n",
       "1              Support Vector Machine                1.000000   \n",
       "2            Decision Tree Classifier                1.000000   \n",
       "3            Random Forest classifier                0.999375   \n",
       "4                    Ridge Classifier                0.973750   \n",
       "5                      SGD Classifier                0.931250   \n",
       "6      K-Nearest Neighbors Classifier                0.930000   \n",
       "7  Naive Bayes Multinomial Classifier                0.843750   \n",
       "8               ElasticNet Classifier                0.663894   \n",
       "9                    Lasso Classifier                0.639250   \n",
       "\n",
       "   Score on test data  \n",
       "0            0.835000  \n",
       "1            0.120000  \n",
       "2            0.685000  \n",
       "3            0.817500  \n",
       "4            0.745000  \n",
       "5            0.840000  \n",
       "6            0.870000  \n",
       "7            0.805000  \n",
       "8            0.531748  \n",
       "9            0.535359  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score on training data</th>\n",
       "      <th>Score on test data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.931250</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.817500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes Multinomial Classifier</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.973750</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.639250</td>\n",
       "      <td>0.535359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.663894</td>\n",
       "      <td>0.531748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Classifier  Score on training data  \\\n",
       "6      K-Nearest Neighbors Classifier                0.930000   \n",
       "5                      SGD Classifier                0.931250   \n",
       "0      Logistic Regression Classifier                1.000000   \n",
       "3            Random Forest classifier                0.999375   \n",
       "7  Naive Bayes Multinomial Classifier                0.843750   \n",
       "4                    Ridge Classifier                0.973750   \n",
       "2            Decision Tree Classifier                1.000000   \n",
       "9                    Lasso Classifier                0.639250   \n",
       "8               ElasticNet Classifier                0.663894   \n",
       "1              Support Vector Machine                1.000000   \n",
       "\n",
       "   Score on test data  \n",
       "6            0.870000  \n",
       "5            0.840000  \n",
       "0            0.835000  \n",
       "3            0.817500  \n",
       "7            0.805000  \n",
       "4            0.745000  \n",
       "2            0.685000  \n",
       "9            0.535359  \n",
       "8            0.531748  \n",
       "1            0.120000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd.sort_values('Score on test data',ascending=[0])#sort the results by accuracy scores on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview 2: Scaling X feature matrix \n",
    "\n",
    "#### MinMax Scaler does the following:\n",
    "\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "X_scaled = X_std * (max - min) + min\n",
    "\n",
    "#### Standard Scaler scale data to mean=0, std=1.\n",
    "\n",
    "**MaxAbsScaler** works in a very similar fashion, but scales in a way that the training data lies within the range [-1, 1] by dividing through the largest maximum value in each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,MaxAbsScaler\n",
    "\n",
    "scaler_names=['MinMax Scaler','Standard Scaler','MaxAbs Scaler']\n",
    "\n",
    "scalers=[MinMaxScaler(),StandardScaler(),MaxAbsScaler()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With MinMax Scaler, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 68.50% on test data.\n",
      "With Standard Scaler, Logistic Regression Classifier has an accuracy score of :100.00% on train data, and 84.25% on test data.\n",
      "With Standard Scaler, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 67.75% on test data.\n",
      "With MaxAbs Scaler, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 68.75% on test data.\n",
      "With MinMax Scaler, Random Forest classifier has an accuracy score of :99.94% on train data, and 85.25% on test data.\n",
      "With MaxAbs Scaler, Random Forest classifier has an accuracy score of :99.88% on train data, and 81.25% on test data.\n",
      "With Standard Scaler, Random Forest classifier has an accuracy score of :99.81% on train data, and 82.00% on test data.\n",
      "With MinMax Scaler, Logistic Regression Classifier has an accuracy score of :99.50% on train data, and 87.25% on test data.\n",
      "With MaxAbs Scaler, Logistic Regression Classifier has an accuracy score of :99.50% on train data, and 87.25% on test data.\n",
      "With Standard Scaler, Support Vector Machine has an accuracy score of :98.12% on train data, and 90.00% on test data.\n",
      "With Standard Scaler, Ridge Classifier has an accuracy score of :97.31% on train data, and 74.25% on test data.\n",
      "With Standard Scaler, SGD Classifier has an accuracy score of :97.25% on train data, and 86.75% on test data.\n",
      "With MinMax Scaler, Ridge Classifier has an accuracy score of :96.25% on train data, and 79.75% on test data.\n",
      "With MaxAbs Scaler, Ridge Classifier has an accuracy score of :96.25% on train data, and 79.75% on test data.\n",
      "With MaxAbs Scaler, SGD Classifier has an accuracy score of :93.81% on train data, and 83.75% on test data.\n",
      "With MinMax Scaler, K-Nearest Neighbors Classifier has an accuracy score of :93.00% on train data, and 87.00% on test data.\n",
      "With MaxAbs Scaler, K-Nearest Neighbors Classifier has an accuracy score of :93.00% on train data, and 87.00% on test data.\n",
      "With MinMax Scaler, SGD Classifier has an accuracy score of :92.12% on train data, and 83.50% on test data.\n",
      "With Standard Scaler, K-Nearest Neighbors Classifier has an accuracy score of :90.31% on train data, and 85.75% on test data.\n",
      "With MinMax Scaler, Support Vector Machine has an accuracy score of :89.75% on train data, and 86.00% on test data.\n",
      "With MaxAbs Scaler, Support Vector Machine has an accuracy score of :89.75% on train data, and 86.00% on test data.\n",
      "With MinMax Scaler, Naive Bayes Multinomial Classifier has an accuracy score of :83.19% on train data, and 80.75% on test data.\n",
      "With MaxAbs Scaler, Naive Bayes Multinomial Classifier has an accuracy score of :83.19% on train data, and 80.75% on test data.\n",
      "With Standard Scaler, ElasticNet Classifier has an accuracy score of :66.29% on train data, and 55.43% on test data.\n",
      "With MinMax Scaler, ElasticNet Classifier has an accuracy score of :64.99% on train data, and 53.69% on test data.\n",
      "With MaxAbs Scaler, ElasticNet Classifier has an accuracy score of :64.99% on train data, and 53.69% on test data.\n",
      "With Standard Scaler, Lasso Classifier has an accuracy score of :64.58% on train data, and 55.55% on test data.\n",
      "With MinMax Scaler, Lasso Classifier has an accuracy score of :63.93% on train data, and 53.53% on test data.\n",
      "With MaxAbs Scaler, Lasso Classifier has an accuracy score of :63.93% on train data, and 53.53% on test data.\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "scales=zip(scaler_names,scalers)\n",
    "for sn,sc in scales:\n",
    "    scaler=sc.fit(X_train)\n",
    "    X_train_scaled=sc.transform(X_train)\n",
    "    X_test_scaled=sc.transform(X_test)\n",
    "    models=zip(classifier_names,classifiers)\n",
    "    for name,clf in models:\n",
    "        try:#use try to handle exception(erros), there are some models that require the input has to be non-negative, we just skip that model\n",
    "            model=clf.fit(X_train_scaled,y_train)\n",
    "            accuracy_score_train=clf.score(X_train_scaled, y_train)\n",
    "            accuracy_score_test=clf.score(X_test_scaled, y_test)\n",
    "            results.append((sn,name,accuracy_score_train,accuracy_score_test))\n",
    "        except:continue\n",
    "            \n",
    "results.sort(key=lambda x:x[2],reverse=True)\n",
    "\n",
    "for s,n,a,b in results:    \n",
    "    print('With {0}, {1} has an accuracy score of :{2:.2%} on train data, and {3:.2%} on test data.'.format(s,n,a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_pd=pd.DataFrame(results,\n",
    "                        columns=['Scaler','Classifier','Score on training data','Score on test data'\n",
    "                                ])#turn list into pandas dataframe for better display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score on training data</th>\n",
       "      <th>Score on test data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.938125</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.921250</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Naive Bayes Multinomial Classifier</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Naive Bayes Multinomial Classifier</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.662854</td>\n",
       "      <td>0.554297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.536897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.536897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.645785</td>\n",
       "      <td>0.555535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.639271</td>\n",
       "      <td>0.535322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.639271</td>\n",
       "      <td>0.535322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Scaler                          Classifier  \\\n",
       "0     MinMax Scaler            Decision Tree Classifier   \n",
       "1   Standard Scaler      Logistic Regression Classifier   \n",
       "2   Standard Scaler            Decision Tree Classifier   \n",
       "3     MaxAbs Scaler            Decision Tree Classifier   \n",
       "4     MinMax Scaler            Random Forest classifier   \n",
       "5     MaxAbs Scaler            Random Forest classifier   \n",
       "6   Standard Scaler            Random Forest classifier   \n",
       "7     MinMax Scaler      Logistic Regression Classifier   \n",
       "8     MaxAbs Scaler      Logistic Regression Classifier   \n",
       "9   Standard Scaler              Support Vector Machine   \n",
       "10  Standard Scaler                    Ridge Classifier   \n",
       "11  Standard Scaler                      SGD Classifier   \n",
       "12    MinMax Scaler                    Ridge Classifier   \n",
       "13    MaxAbs Scaler                    Ridge Classifier   \n",
       "14    MaxAbs Scaler                      SGD Classifier   \n",
       "15    MinMax Scaler      K-Nearest Neighbors Classifier   \n",
       "16    MaxAbs Scaler      K-Nearest Neighbors Classifier   \n",
       "17    MinMax Scaler                      SGD Classifier   \n",
       "18  Standard Scaler      K-Nearest Neighbors Classifier   \n",
       "19    MinMax Scaler              Support Vector Machine   \n",
       "20    MaxAbs Scaler              Support Vector Machine   \n",
       "21    MinMax Scaler  Naive Bayes Multinomial Classifier   \n",
       "22    MaxAbs Scaler  Naive Bayes Multinomial Classifier   \n",
       "23  Standard Scaler               ElasticNet Classifier   \n",
       "24    MinMax Scaler               ElasticNet Classifier   \n",
       "25    MaxAbs Scaler               ElasticNet Classifier   \n",
       "26  Standard Scaler                    Lasso Classifier   \n",
       "27    MinMax Scaler                    Lasso Classifier   \n",
       "28    MaxAbs Scaler                    Lasso Classifier   \n",
       "\n",
       "    Score on training data  Score on test data  \n",
       "0                 1.000000            0.685000  \n",
       "1                 1.000000            0.842500  \n",
       "2                 1.000000            0.677500  \n",
       "3                 1.000000            0.687500  \n",
       "4                 0.999375            0.852500  \n",
       "5                 0.998750            0.812500  \n",
       "6                 0.998125            0.820000  \n",
       "7                 0.995000            0.872500  \n",
       "8                 0.995000            0.872500  \n",
       "9                 0.981250            0.900000  \n",
       "10                0.973125            0.742500  \n",
       "11                0.972500            0.867500  \n",
       "12                0.962500            0.797500  \n",
       "13                0.962500            0.797500  \n",
       "14                0.938125            0.837500  \n",
       "15                0.930000            0.870000  \n",
       "16                0.930000            0.870000  \n",
       "17                0.921250            0.835000  \n",
       "18                0.903125            0.857500  \n",
       "19                0.897500            0.860000  \n",
       "20                0.897500            0.860000  \n",
       "21                0.831875            0.807500  \n",
       "22                0.831875            0.807500  \n",
       "23                0.662854            0.554297  \n",
       "24                0.649891            0.536897  \n",
       "25                0.649891            0.536897  \n",
       "26                0.645785            0.555535  \n",
       "27                0.639271            0.535322  \n",
       "28                0.639271            0.535322  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score on training data</th>\n",
       "      <th>Score on test data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.938125</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.921250</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Naive Bayes Multinomial Classifier</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Naive Bayes Multinomial Classifier</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.645785</td>\n",
       "      <td>0.555535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.662854</td>\n",
       "      <td>0.554297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.536897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.536897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.639271</td>\n",
       "      <td>0.535322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.639271</td>\n",
       "      <td>0.535322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Scaler                          Classifier  \\\n",
       "9   Standard Scaler              Support Vector Machine   \n",
       "7     MinMax Scaler      Logistic Regression Classifier   \n",
       "8     MaxAbs Scaler      Logistic Regression Classifier   \n",
       "16    MaxAbs Scaler      K-Nearest Neighbors Classifier   \n",
       "15    MinMax Scaler      K-Nearest Neighbors Classifier   \n",
       "11  Standard Scaler                      SGD Classifier   \n",
       "20    MaxAbs Scaler              Support Vector Machine   \n",
       "19    MinMax Scaler              Support Vector Machine   \n",
       "18  Standard Scaler      K-Nearest Neighbors Classifier   \n",
       "4     MinMax Scaler            Random Forest classifier   \n",
       "1   Standard Scaler      Logistic Regression Classifier   \n",
       "14    MaxAbs Scaler                      SGD Classifier   \n",
       "17    MinMax Scaler                      SGD Classifier   \n",
       "6   Standard Scaler            Random Forest classifier   \n",
       "5     MaxAbs Scaler            Random Forest classifier   \n",
       "21    MinMax Scaler  Naive Bayes Multinomial Classifier   \n",
       "22    MaxAbs Scaler  Naive Bayes Multinomial Classifier   \n",
       "12    MinMax Scaler                    Ridge Classifier   \n",
       "13    MaxAbs Scaler                    Ridge Classifier   \n",
       "10  Standard Scaler                    Ridge Classifier   \n",
       "3     MaxAbs Scaler            Decision Tree Classifier   \n",
       "0     MinMax Scaler            Decision Tree Classifier   \n",
       "2   Standard Scaler            Decision Tree Classifier   \n",
       "26  Standard Scaler                    Lasso Classifier   \n",
       "23  Standard Scaler               ElasticNet Classifier   \n",
       "24    MinMax Scaler               ElasticNet Classifier   \n",
       "25    MaxAbs Scaler               ElasticNet Classifier   \n",
       "27    MinMax Scaler                    Lasso Classifier   \n",
       "28    MaxAbs Scaler                    Lasso Classifier   \n",
       "\n",
       "    Score on training data  Score on test data  \n",
       "9                 0.981250            0.900000  \n",
       "7                 0.995000            0.872500  \n",
       "8                 0.995000            0.872500  \n",
       "16                0.930000            0.870000  \n",
       "15                0.930000            0.870000  \n",
       "11                0.972500            0.867500  \n",
       "20                0.897500            0.860000  \n",
       "19                0.897500            0.860000  \n",
       "18                0.903125            0.857500  \n",
       "4                 0.999375            0.852500  \n",
       "1                 1.000000            0.842500  \n",
       "14                0.938125            0.837500  \n",
       "17                0.921250            0.835000  \n",
       "6                 0.998125            0.820000  \n",
       "5                 0.998750            0.812500  \n",
       "21                0.831875            0.807500  \n",
       "22                0.831875            0.807500  \n",
       "12                0.962500            0.797500  \n",
       "13                0.962500            0.797500  \n",
       "10                0.973125            0.742500  \n",
       "3                 1.000000            0.687500  \n",
       "0                 1.000000            0.685000  \n",
       "2                 1.000000            0.677500  \n",
       "26                0.645785            0.555535  \n",
       "23                0.662854            0.554297  \n",
       "24                0.649891            0.536897  \n",
       "25                0.649891            0.536897  \n",
       "27                0.639271            0.535322  \n",
       "28                0.639271            0.535322  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd.sort_values('Score on test data',ascending=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scaler</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score on training data</th>\n",
       "      <th>Score on test data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.938125</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Naive Bayes Multinomial Classifier</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.536897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MaxAbs Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.639271</td>\n",
       "      <td>0.535322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.872500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.852500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.921250</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Naive Bayes Multinomial Classifier</td>\n",
       "      <td>0.831875</td>\n",
       "      <td>0.807500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.962500</td>\n",
       "      <td>0.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.649891</td>\n",
       "      <td>0.536897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MinMax Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.639271</td>\n",
       "      <td>0.535322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.972500</td>\n",
       "      <td>0.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.973125</td>\n",
       "      <td>0.742500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.645785</td>\n",
       "      <td>0.555535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Standard Scaler</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.662854</td>\n",
       "      <td>0.554297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Scaler                          Classifier  \\\n",
       "8     MaxAbs Scaler      Logistic Regression Classifier   \n",
       "16    MaxAbs Scaler      K-Nearest Neighbors Classifier   \n",
       "20    MaxAbs Scaler              Support Vector Machine   \n",
       "14    MaxAbs Scaler                      SGD Classifier   \n",
       "5     MaxAbs Scaler            Random Forest classifier   \n",
       "22    MaxAbs Scaler  Naive Bayes Multinomial Classifier   \n",
       "13    MaxAbs Scaler                    Ridge Classifier   \n",
       "3     MaxAbs Scaler            Decision Tree Classifier   \n",
       "25    MaxAbs Scaler               ElasticNet Classifier   \n",
       "28    MaxAbs Scaler                    Lasso Classifier   \n",
       "7     MinMax Scaler      Logistic Regression Classifier   \n",
       "15    MinMax Scaler      K-Nearest Neighbors Classifier   \n",
       "19    MinMax Scaler              Support Vector Machine   \n",
       "4     MinMax Scaler            Random Forest classifier   \n",
       "17    MinMax Scaler                      SGD Classifier   \n",
       "21    MinMax Scaler  Naive Bayes Multinomial Classifier   \n",
       "12    MinMax Scaler                    Ridge Classifier   \n",
       "0     MinMax Scaler            Decision Tree Classifier   \n",
       "24    MinMax Scaler               ElasticNet Classifier   \n",
       "27    MinMax Scaler                    Lasso Classifier   \n",
       "9   Standard Scaler              Support Vector Machine   \n",
       "11  Standard Scaler                      SGD Classifier   \n",
       "18  Standard Scaler      K-Nearest Neighbors Classifier   \n",
       "1   Standard Scaler      Logistic Regression Classifier   \n",
       "6   Standard Scaler            Random Forest classifier   \n",
       "10  Standard Scaler                    Ridge Classifier   \n",
       "2   Standard Scaler            Decision Tree Classifier   \n",
       "26  Standard Scaler                    Lasso Classifier   \n",
       "23  Standard Scaler               ElasticNet Classifier   \n",
       "\n",
       "    Score on training data  Score on test data  \n",
       "8                 0.995000            0.872500  \n",
       "16                0.930000            0.870000  \n",
       "20                0.897500            0.860000  \n",
       "14                0.938125            0.837500  \n",
       "5                 0.998750            0.812500  \n",
       "22                0.831875            0.807500  \n",
       "13                0.962500            0.797500  \n",
       "3                 1.000000            0.687500  \n",
       "25                0.649891            0.536897  \n",
       "28                0.639271            0.535322  \n",
       "7                 0.995000            0.872500  \n",
       "15                0.930000            0.870000  \n",
       "19                0.897500            0.860000  \n",
       "4                 0.999375            0.852500  \n",
       "17                0.921250            0.835000  \n",
       "21                0.831875            0.807500  \n",
       "12                0.962500            0.797500  \n",
       "0                 1.000000            0.685000  \n",
       "24                0.649891            0.536897  \n",
       "27                0.639271            0.535322  \n",
       "9                 0.981250            0.900000  \n",
       "11                0.972500            0.867500  \n",
       "18                0.903125            0.857500  \n",
       "1                 1.000000            0.842500  \n",
       "6                 0.998125            0.820000  \n",
       "10                0.973125            0.742500  \n",
       "2                 1.000000            0.677500  \n",
       "26                0.645785            0.555535  \n",
       "23                0.662854            0.554297  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd.sort_values(['Scaler','Score on test data'],\n",
    "                       ascending=[1,0])#sort by scaler ascendingly first, then by test score descendingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview 3: PCA Transforming X feature matrix \n",
    "\n",
    "There are 784 features and the models could be very complex, in reality we face complexity and accuracy tradeoff.\n",
    "With PCA(principle component analysis) we could reduce dimensionality (you can understand here as number of features) and try to keep most of the information of the original data, if not all, and still get an acceptable (sometime better) accuracy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "COMPONENT_NUM=range(10,200,20)#create of list of numbers in the range of 10 to 200, by the step of 20, that is, 10,30,50,...\n",
    "\n",
    "classifier_names=['K-Nearest Neighbors Classifier',\n",
    "                    'Logistic Regression Classifier',\n",
    "                    'Ridge Classifier',\n",
    "                    'Lasso Classifier',\n",
    "                    'SGD Classifier',\n",
    "                    'ElasticNet Classifier',\n",
    "                    'Support Vector Machine',\n",
    "                    'Decision Tree Classifier',\n",
    "                    'Random Forest classifier']\n",
    "\n",
    "classifiers = [ KNeighborsClassifier(),\n",
    "                LogisticRegression(),\n",
    "                RidgeClassifier(),\n",
    "                LassoCV(),\n",
    "                SGDClassifier(),           \n",
    "                ElasticNetCV(cv=10, random_state=0),\n",
    "                SVC(),\n",
    "                DecisionTreeClassifier(),           \n",
    "                RandomForestClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\micha\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 70 components, Support Vector Machine has an accuracy score of :99.62% on train data, and 91.75% on test data.\n",
      "With 30 components, Support Vector Machine has an accuracy score of :98.44% on train data, and 91.50% on test data.\n",
      "With 50 components, Support Vector Machine has an accuracy score of :99.50% on train data, and 91.50% on test data.\n",
      "With 90 components, Support Vector Machine has an accuracy score of :99.75% on train data, and 91.00% on test data.\n",
      "With 110 components, Support Vector Machine has an accuracy score of :99.81% on train data, and 91.00% on test data.\n",
      "With 130 components, Support Vector Machine has an accuracy score of :99.75% on train data, and 90.50% on test data.\n",
      "With 150 components, Support Vector Machine has an accuracy score of :99.81% on train data, and 90.50% on test data.\n",
      "With 190 components, Support Vector Machine has an accuracy score of :99.88% on train data, and 90.25% on test data.\n",
      "With 170 components, Support Vector Machine has an accuracy score of :99.88% on train data, and 89.75% on test data.\n",
      "With 10 components, Support Vector Machine has an accuracy score of :92.94% on train data, and 88.00% on test data.\n",
      "With 50 components, Logistic Regression Classifier has an accuracy score of :91.44% on train data, and 87.50% on test data.\n",
      "With 90 components, Logistic Regression Classifier has an accuracy score of :94.19% on train data, and 87.50% on test data.\n",
      "With 50 components, SGD Classifier has an accuracy score of :89.50% on train data, and 87.00% on test data.\n",
      "With 30 components, Logistic Regression Classifier has an accuracy score of :88.44% on train data, and 86.75% on test data.\n",
      "With 70 components, Logistic Regression Classifier has an accuracy score of :92.88% on train data, and 86.50% on test data.\n",
      "With 30 components, K-Nearest Neighbors Classifier has an accuracy score of :93.56% on train data, and 86.00% on test data.\n",
      "With 110 components, Logistic Regression Classifier has an accuracy score of :96.81% on train data, and 85.75% on test data.\n",
      "With 10 components, K-Nearest Neighbors Classifier has an accuracy score of :90.50% on train data, and 84.75% on test data.\n",
      "With 90 components, SGD Classifier has an accuracy score of :92.75% on train data, and 84.75% on test data.\n",
      "With 50 components, Ridge Classifier has an accuracy score of :85.38% on train data, and 84.25% on test data.\n",
      "With 150 components, Logistic Regression Classifier has an accuracy score of :98.12% on train data, and 84.25% on test data.\n",
      "With 170 components, Logistic Regression Classifier has an accuracy score of :99.06% on train data, and 84.25% on test data.\n",
      "With 50 components, K-Nearest Neighbors Classifier has an accuracy score of :91.19% on train data, and 84.00% on test data.\n",
      "With 130 components, Logistic Regression Classifier has an accuracy score of :97.81% on train data, and 84.00% on test data.\n",
      "With 130 components, Ridge Classifier has an accuracy score of :88.62% on train data, and 83.75% on test data.\n",
      "With 130 components, SGD Classifier has an accuracy score of :94.81% on train data, and 83.75% on test data.\n",
      "With 30 components, Random Forest classifier has an accuracy score of :99.94% on train data, and 83.50% on test data.\n",
      "With 70 components, Ridge Classifier has an accuracy score of :86.81% on train data, and 83.50% on test data.\n",
      "With 110 components, SGD Classifier has an accuracy score of :93.94% on train data, and 83.50% on test data.\n",
      "With 90 components, Ridge Classifier has an accuracy score of :87.88% on train data, and 83.25% on test data.\n",
      "With 70 components, SGD Classifier has an accuracy score of :90.25% on train data, and 83.00% on test data.\n",
      "With 110 components, Ridge Classifier has an accuracy score of :88.88% on train data, and 83.00% on test data.\n",
      "With 190 components, Logistic Regression Classifier has an accuracy score of :99.62% on train data, and 83.00% on test data.\n",
      "With 30 components, SGD Classifier has an accuracy score of :87.38% on train data, and 82.50% on test data.\n",
      "With 170 components, Ridge Classifier has an accuracy score of :89.94% on train data, and 82.50% on test data.\n",
      "With 190 components, Ridge Classifier has an accuracy score of :90.44% on train data, and 82.50% on test data.\n",
      "With 150 components, Ridge Classifier has an accuracy score of :89.31% on train data, and 82.00% on test data.\n",
      "With 170 components, SGD Classifier has an accuracy score of :97.12% on train data, and 82.00% on test data.\n",
      "With 30 components, Ridge Classifier has an accuracy score of :81.88% on train data, and 81.50% on test data.\n",
      "With 10 components, Random Forest classifier has an accuracy score of :99.44% on train data, and 80.75% on test data.\n",
      "With 150 components, SGD Classifier has an accuracy score of :96.44% on train data, and 80.50% on test data.\n",
      "With 70 components, K-Nearest Neighbors Classifier has an accuracy score of :87.50% on train data, and 79.25% on test data.\n",
      "With 190 components, SGD Classifier has an accuracy score of :97.31% on train data, and 78.75% on test data.\n",
      "With 50 components, Random Forest classifier has an accuracy score of :99.62% on train data, and 78.00% on test data.\n",
      "With 90 components, Random Forest classifier has an accuracy score of :100.00% on train data, and 76.75% on test data.\n",
      "With 10 components, Logistic Regression Classifier has an accuracy score of :77.88% on train data, and 76.25% on test data.\n",
      "With 10 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 74.50% on test data.\n",
      "With 70 components, Random Forest classifier has an accuracy score of :99.94% on train data, and 73.75% on test data.\n",
      "With 90 components, K-Nearest Neighbors Classifier has an accuracy score of :81.44% on train data, and 73.75% on test data.\n",
      "With 130 components, Random Forest classifier has an accuracy score of :99.69% on train data, and 72.00% on test data.\n",
      "With 50 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 70.75% on test data.\n",
      "With 10 components, SGD Classifier has an accuracy score of :73.69% on train data, and 70.50% on test data.\n",
      "With 10 components, Ridge Classifier has an accuracy score of :70.06% on train data, and 70.25% on test data.\n",
      "With 30 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 70.00% on test data.\n",
      "With 110 components, Random Forest classifier has an accuracy score of :99.81% on train data, and 69.00% on test data.\n",
      "With 70 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 68.25% on test data.\n",
      "With 90 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 68.25% on test data.\n",
      "With 170 components, Random Forest classifier has an accuracy score of :99.94% on train data, and 68.25% on test data.\n",
      "With 150 components, Random Forest classifier has an accuracy score of :100.00% on train data, and 67.75% on test data.\n",
      "With 110 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 67.25% on test data.\n",
      "With 170 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 66.75% on test data.\n",
      "With 130 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 66.50% on test data.\n",
      "With 150 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 66.50% on test data.\n",
      "With 190 components, Decision Tree Classifier has an accuracy score of :100.00% on train data, and 66.50% on test data.\n",
      "With 110 components, K-Nearest Neighbors Classifier has an accuracy score of :76.19% on train data, and 64.75% on test data.\n",
      "With 190 components, Random Forest classifier has an accuracy score of :99.88% on train data, and 59.25% on test data.\n",
      "With 130 components, K-Nearest Neighbors Classifier has an accuracy score of :67.12% on train data, and 56.75% on test data.\n",
      "With 190 components, Lasso Classifier has an accuracy score of :62.57% on train data, and 54.75% on test data.\n",
      "With 190 components, ElasticNet Classifier has an accuracy score of :63.48% on train data, and 54.55% on test data.\n",
      "With 150 components, Lasso Classifier has an accuracy score of :61.72% on train data, and 54.43% on test data.\n",
      "With 170 components, Lasso Classifier has an accuracy score of :62.19% on train data, and 54.36% on test data.\n",
      "With 70 components, Lasso Classifier has an accuracy score of :59.55% on train data, and 54.33% on test data.\n",
      "With 150 components, ElasticNet Classifier has an accuracy score of :62.19% on train data, and 54.22% on test data.\n",
      "With 130 components, Lasso Classifier has an accuracy score of :61.62% on train data, and 54.17% on test data.\n",
      "With 70 components, ElasticNet Classifier has an accuracy score of :59.73% on train data, and 54.15% on test data.\n",
      "With 170 components, ElasticNet Classifier has an accuracy score of :63.00% on train data, and 54.06% on test data.\n",
      "With 130 components, ElasticNet Classifier has an accuracy score of :62.05% on train data, and 53.92% on test data.\n",
      "With 90 components, Lasso Classifier has an accuracy score of :60.81% on train data, and 53.85% on test data.\n",
      "With 110 components, Lasso Classifier has an accuracy score of :61.61% on train data, and 53.70% on test data.\n",
      "With 90 components, ElasticNet Classifier has an accuracy score of :61.21% on train data, and 53.49% on test data.\n",
      "With 110 components, ElasticNet Classifier has an accuracy score of :61.88% on train data, and 53.49% on test data.\n",
      "With 50 components, Lasso Classifier has an accuracy score of :55.95% on train data, and 51.25% on test data.\n",
      "With 50 components, ElasticNet Classifier has an accuracy score of :56.14% on train data, and 50.93% on test data.\n",
      "With 30 components, Lasso Classifier has an accuracy score of :52.97% on train data, and 49.80% on test data.\n",
      "With 30 components, ElasticNet Classifier has an accuracy score of :53.07% on train data, and 49.57% on test data.\n",
      "With 150 components, K-Nearest Neighbors Classifier has an accuracy score of :59.50% on train data, and 48.00% on test data.\n",
      "With 10 components, ElasticNet Classifier has an accuracy score of :41.14% on train data, and 46.53% on test data.\n",
      "With 10 components, Lasso Classifier has an accuracy score of :41.06% on train data, and 46.35% on test data.\n",
      "With 170 components, K-Nearest Neighbors Classifier has an accuracy score of :49.44% on train data, and 41.25% on test data.\n",
      "With 190 components, K-Nearest Neighbors Classifier has an accuracy score of :41.06% on train data, and 35.50% on test data.\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "for n in COMPONENT_NUM:\n",
    "    pca = PCA(n_components=n, whiten=True)#whiten=True to remove outliers \n",
    "    pca.fit(X_train)\n",
    "    X_train_pca=pca.transform(X_train) #pca transform on training data\n",
    "    X_test_pca=pca.transform(X_test) #you have to do the same transformation on test data\n",
    "    \n",
    "    models=zip(classifier_names,classifiers)\n",
    "    for name,clf in models:\n",
    "        model=clf.fit(X_train_pca,y_train)\n",
    "        accuracy_score_train=clf.score(X_train_pca, y_train)\n",
    "        accuracy_score_test=clf.score(X_test_pca, y_test)\n",
    "        results.append((n,name,accuracy_score_train,accuracy_score_test))\n",
    "\n",
    "results.sort(key=lambda x:x[3],reverse=True)\n",
    "\n",
    "for n,name,a,b in results:    \n",
    "    print('With {0} components, {1} has an accuracy score of :{2:.2%} on train data, and {3:.2%} on test data.'.format(n,name,a,b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "results_pd=pd.DataFrame(results,\n",
    "                        columns=['Number of components','Classifier','Score on training data','Score on test data'\n",
    "                                ])#turn list into pandas dataframe for better display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of components</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score on training data</th>\n",
       "      <th>Score on test data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.996250</td>\n",
       "      <td>0.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>190</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.897500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.929375</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.914375</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>90</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.941875</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>30</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>70</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.928750</td>\n",
       "      <td>0.865000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.935625</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>110</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.968125</td>\n",
       "      <td>0.857500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>90</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.927500</td>\n",
       "      <td>0.847500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>50</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.853750</td>\n",
       "      <td>0.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>150</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.981250</td>\n",
       "      <td>0.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>170</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.990625</td>\n",
       "      <td>0.842500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>50</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.911875</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>130</td>\n",
       "      <td>Logistic Regression Classifier</td>\n",
       "      <td>0.978125</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>130</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.886250</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>130</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.948125</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.999375</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>70</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.868125</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>110</td>\n",
       "      <td>SGD Classifier</td>\n",
       "      <td>0.939375</td>\n",
       "      <td>0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>90</td>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>0.878750</td>\n",
       "      <td>0.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>170</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>130</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>150</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>190</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>110</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.761875</td>\n",
       "      <td>0.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>190</td>\n",
       "      <td>Random Forest classifier</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>130</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.671250</td>\n",
       "      <td>0.567500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>190</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.625705</td>\n",
       "      <td>0.547528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>190</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.634777</td>\n",
       "      <td>0.545490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>150</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.617193</td>\n",
       "      <td>0.544281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>170</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.621895</td>\n",
       "      <td>0.543619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>70</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.595476</td>\n",
       "      <td>0.543332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>150</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.621878</td>\n",
       "      <td>0.542220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>130</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.616223</td>\n",
       "      <td>0.541702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>70</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.597276</td>\n",
       "      <td>0.541516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>170</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.630002</td>\n",
       "      <td>0.540553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>130</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.620494</td>\n",
       "      <td>0.539247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>90</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.608107</td>\n",
       "      <td>0.538474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>110</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.616092</td>\n",
       "      <td>0.537041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>90</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.612083</td>\n",
       "      <td>0.534891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>110</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.618783</td>\n",
       "      <td>0.534860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>50</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.559488</td>\n",
       "      <td>0.512541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>50</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.561375</td>\n",
       "      <td>0.509301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>30</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.529675</td>\n",
       "      <td>0.498006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>30</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.530714</td>\n",
       "      <td>0.495723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>150</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>10</td>\n",
       "      <td>ElasticNet Classifier</td>\n",
       "      <td>0.411448</td>\n",
       "      <td>0.465298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>10</td>\n",
       "      <td>Lasso Classifier</td>\n",
       "      <td>0.410633</td>\n",
       "      <td>0.463493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>170</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.494375</td>\n",
       "      <td>0.412500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>190</td>\n",
       "      <td>K-Nearest Neighbors Classifier</td>\n",
       "      <td>0.410625</td>\n",
       "      <td>0.355000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Number of components                      Classifier  \\\n",
       "0                     70          Support Vector Machine   \n",
       "1                     30          Support Vector Machine   \n",
       "2                     50          Support Vector Machine   \n",
       "3                     90          Support Vector Machine   \n",
       "4                    110          Support Vector Machine   \n",
       "5                    130          Support Vector Machine   \n",
       "6                    150          Support Vector Machine   \n",
       "7                    190          Support Vector Machine   \n",
       "8                    170          Support Vector Machine   \n",
       "9                     10          Support Vector Machine   \n",
       "10                    50  Logistic Regression Classifier   \n",
       "11                    90  Logistic Regression Classifier   \n",
       "12                    50                  SGD Classifier   \n",
       "13                    30  Logistic Regression Classifier   \n",
       "14                    70  Logistic Regression Classifier   \n",
       "15                    30  K-Nearest Neighbors Classifier   \n",
       "16                   110  Logistic Regression Classifier   \n",
       "17                    10  K-Nearest Neighbors Classifier   \n",
       "18                    90                  SGD Classifier   \n",
       "19                    50                Ridge Classifier   \n",
       "20                   150  Logistic Regression Classifier   \n",
       "21                   170  Logistic Regression Classifier   \n",
       "22                    50  K-Nearest Neighbors Classifier   \n",
       "23                   130  Logistic Regression Classifier   \n",
       "24                   130                Ridge Classifier   \n",
       "25                   130                  SGD Classifier   \n",
       "26                    30        Random Forest classifier   \n",
       "27                    70                Ridge Classifier   \n",
       "28                   110                  SGD Classifier   \n",
       "29                    90                Ridge Classifier   \n",
       "..                   ...                             ...   \n",
       "60                   170        Decision Tree Classifier   \n",
       "61                   130        Decision Tree Classifier   \n",
       "62                   150        Decision Tree Classifier   \n",
       "63                   190        Decision Tree Classifier   \n",
       "64                   110  K-Nearest Neighbors Classifier   \n",
       "65                   190        Random Forest classifier   \n",
       "66                   130  K-Nearest Neighbors Classifier   \n",
       "67                   190                Lasso Classifier   \n",
       "68                   190           ElasticNet Classifier   \n",
       "69                   150                Lasso Classifier   \n",
       "70                   170                Lasso Classifier   \n",
       "71                    70                Lasso Classifier   \n",
       "72                   150           ElasticNet Classifier   \n",
       "73                   130                Lasso Classifier   \n",
       "74                    70           ElasticNet Classifier   \n",
       "75                   170           ElasticNet Classifier   \n",
       "76                   130           ElasticNet Classifier   \n",
       "77                    90                Lasso Classifier   \n",
       "78                   110                Lasso Classifier   \n",
       "79                    90           ElasticNet Classifier   \n",
       "80                   110           ElasticNet Classifier   \n",
       "81                    50                Lasso Classifier   \n",
       "82                    50           ElasticNet Classifier   \n",
       "83                    30                Lasso Classifier   \n",
       "84                    30           ElasticNet Classifier   \n",
       "85                   150  K-Nearest Neighbors Classifier   \n",
       "86                    10           ElasticNet Classifier   \n",
       "87                    10                Lasso Classifier   \n",
       "88                   170  K-Nearest Neighbors Classifier   \n",
       "89                   190  K-Nearest Neighbors Classifier   \n",
       "\n",
       "    Score on training data  Score on test data  \n",
       "0                 0.996250            0.917500  \n",
       "1                 0.984375            0.915000  \n",
       "2                 0.995000            0.915000  \n",
       "3                 0.997500            0.910000  \n",
       "4                 0.998125            0.910000  \n",
       "5                 0.997500            0.905000  \n",
       "6                 0.998125            0.905000  \n",
       "7                 0.998750            0.902500  \n",
       "8                 0.998750            0.897500  \n",
       "9                 0.929375            0.880000  \n",
       "10                0.914375            0.875000  \n",
       "11                0.941875            0.875000  \n",
       "12                0.895000            0.870000  \n",
       "13                0.884375            0.867500  \n",
       "14                0.928750            0.865000  \n",
       "15                0.935625            0.860000  \n",
       "16                0.968125            0.857500  \n",
       "17                0.905000            0.847500  \n",
       "18                0.927500            0.847500  \n",
       "19                0.853750            0.842500  \n",
       "20                0.981250            0.842500  \n",
       "21                0.990625            0.842500  \n",
       "22                0.911875            0.840000  \n",
       "23                0.978125            0.840000  \n",
       "24                0.886250            0.837500  \n",
       "25                0.948125            0.837500  \n",
       "26                0.999375            0.835000  \n",
       "27                0.868125            0.835000  \n",
       "28                0.939375            0.835000  \n",
       "29                0.878750            0.832500  \n",
       "..                     ...                 ...  \n",
       "60                1.000000            0.667500  \n",
       "61                1.000000            0.665000  \n",
       "62                1.000000            0.665000  \n",
       "63                1.000000            0.665000  \n",
       "64                0.761875            0.647500  \n",
       "65                0.998750            0.592500  \n",
       "66                0.671250            0.567500  \n",
       "67                0.625705            0.547528  \n",
       "68                0.634777            0.545490  \n",
       "69                0.617193            0.544281  \n",
       "70                0.621895            0.543619  \n",
       "71                0.595476            0.543332  \n",
       "72                0.621878            0.542220  \n",
       "73                0.616223            0.541702  \n",
       "74                0.597276            0.541516  \n",
       "75                0.630002            0.540553  \n",
       "76                0.620494            0.539247  \n",
       "77                0.608107            0.538474  \n",
       "78                0.616092            0.537041  \n",
       "79                0.612083            0.534891  \n",
       "80                0.618783            0.534860  \n",
       "81                0.559488            0.512541  \n",
       "82                0.561375            0.509301  \n",
       "83                0.529675            0.498006  \n",
       "84                0.530714            0.495723  \n",
       "85                0.595000            0.480000  \n",
       "86                0.411448            0.465298  \n",
       "87                0.410633            0.463493  \n",
       "88                0.494375            0.412500  \n",
       "89                0.410625            0.355000  \n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "svm_re=results_pd[results_pd['Classifier']=='Support Vector Machine'].sort_values(['Number of components'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of components</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Score on training data</th>\n",
       "      <th>Score on test data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.929375</td>\n",
       "      <td>0.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.9150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.9150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.996250</td>\n",
       "      <td>0.9175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>130</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>0.9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.998125</td>\n",
       "      <td>0.9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>170</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>190</td>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.9025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of components              Classifier  Score on training data  \\\n",
       "9                    10  Support Vector Machine                0.929375   \n",
       "1                    30  Support Vector Machine                0.984375   \n",
       "2                    50  Support Vector Machine                0.995000   \n",
       "0                    70  Support Vector Machine                0.996250   \n",
       "3                    90  Support Vector Machine                0.997500   \n",
       "4                   110  Support Vector Machine                0.998125   \n",
       "5                   130  Support Vector Machine                0.997500   \n",
       "6                   150  Support Vector Machine                0.998125   \n",
       "8                   170  Support Vector Machine                0.998750   \n",
       "7                   190  Support Vector Machine                0.998750   \n",
       "\n",
       "   Score on test data  \n",
       "9              0.8800  \n",
       "1              0.9150  \n",
       "2              0.9150  \n",
       "0              0.9175  \n",
       "3              0.9100  \n",
       "4              0.9100  \n",
       "5              0.9050  \n",
       "6              0.9050  \n",
       "8              0.8975  \n",
       "7              0.9025  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Support Vector Machine with n PCA Components')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "\n",
    "axes.plot(svm_re['Number of components'], svm_re['Score on training data'], 'r',label='Train')\n",
    "axes.set_xlabel('Number of components')\n",
    "axes.set_ylabel('Accuracy')\n",
    "axes.plot(svm_re['Number of components'], svm_re['Score on test data'], 'b',label='Test')\n",
    "axes.legend()\n",
    "axes.set_title('Support Vector Machine with n PCA Components')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview 4: Grid Search\n",
    "\n",
    "For each model, there are parameters to be set, sometimes, these parameters have great impact on the resulting accuracy.\n",
    "We can use grid search to automate the selection of parameters in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy  on train data is 0.991875, and 0.92 on test dataset.\n",
      "The best parameters are: {'C': 10, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svc=SVC()\n",
    "\n",
    "parameters={'gamma':[0.001,0.01,0.1,1,10,100], 'C':[0.001,0.01,0.1,1, 10,100]}\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "\n",
    "pca = PCA(n_components=30, whiten=True)\n",
    "pca.fit(X_train)\n",
    "X_train_pca=pca.transform(X_train)\n",
    "X_test_pca=pca.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_pca,y_train)\n",
    "\n",
    "print('The accuracy  on train data is {0}, and {1} on test dataset.'.format(clf.score(X_train_pca,y_train),clf.score(X_test_pca,y_test)))\n",
    "\n",
    "print('The best parameters are: {0}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch with 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy  on train data is 0.991875, and 0.92 on test dataset.\n",
      "The best parameters are: {'C': 10, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "svc=SVC()\n",
    "\n",
    "parameters={'gamma':[0.001,0.01,0.1,1,10,100], 'C':[0.001,0.01,0.1,1, 10,100]}\n",
    "clf = GridSearchCV(svc, parameters,cv=5)\n",
    "\n",
    "pca = PCA(n_components=30, whiten=True)\n",
    "pca.fit(X_train)\n",
    "X_train_pca=pca.transform(X_train)\n",
    "X_test_pca=pca.transform(X_test)\n",
    "\n",
    "clf.fit(X_train_pca,y_train)\n",
    "\n",
    "print('The accuracy  on train data is {0}, and {1} on test dataset.'.format(clf.score(X_train_pca,y_train),clf.score(X_test_pca,y_test)))\n",
    "\n",
    "print('The best parameters are: {0}'.format(clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember, you use only 2,000 sample from 42,000 samples!\n",
    "\n",
    "Now, please go back the very beginning, and change the number of sample to be used into 4,000 (still a small portion of the whole dataset), and repeat all the steps you have tried, and find out how much the performance (accuracy rate) of the models have been changed.\n",
    "\n",
    "Before you repeat all the steps from above, copy the results from 2000 samples and save in a file, or save in a pd dataframe with different names."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
